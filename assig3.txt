!pip install tensorflow
# Step 1: Import Required Libraries
# ----------------------------
import numpy as np
import matplotlib.pyplot as plt

# TensorFlow / Keras
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical

# Sklearn for preprocessing and train-test split
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import classification_report

# Step 2: Load CIFAR-10 Dataset
# ----------------------------
# CIFAR-10 dataset has 60,000 images of size 32x32x3 in 10 classes
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()

# Optional: use smaller subset for faster training
X_train, y_train = X_train[:10000], y_train[:10000]
X_test, y_test = X_test[:2000], y_test[:2000]

print("Training data shape:", X_train.shape, y_train.shape)
print("Testing data shape:", X_test.shape, y_test.shape)


# Step 3: Preprocess Data
# ----------------------------
# Normalize pixel values to [0,1] range
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# Convert labels to one-hot encoding
num_classes = 10
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)

# Split training set into train + validation sets
X_train, X_val, y_train, y_val = train_test_split(
    X_train, y_train, test_size=0.2, random_state=42
)

print("Train set:", X_train.shape, y_train.shape)
print("Validation set:", X_val.shape, y_val.shape)


# Step 4: Define CNN Model Architecture
# ----------------------------
model = Sequential()

# Input layer (modern Keras style)
model.add(Input(shape=(32, 32, 3)))

# First Convolutional Layer
model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D((2, 2)))

# Second Convolutional Layer
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(MaxPooling2D((2, 2)))

# Third Convolutional Layer
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))

# Flatten feature maps to feed into Dense layers
model.add(Flatten())

# Fully connected Dense layer
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))  # Prevent overfitting

# Output layer for 10 classes
model.add(Dense(num_classes, activation='softmax'))

# Step 5: Compile the Model
# ----------------------------
model.compile(
    optimizer='adam',                    # Adaptive optimizer
    loss='categorical_crossentropy',     # Multi-class classification loss
    metrics=['accuracy']                 # Track training/validation accuracy
)

# Display model architecture
model.summary()


# Step 6: Train the CNN Model
# ----------------------------
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=10,             # Number of training passes
    batch_size=64,         # Number of samples per gradient update
    verbose=1
)


# Step 7: Evaluate Model on Test Data
# ----------------------------
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print("âœ… Test Accuracy:", round(test_acc * 100, 2), "%")
print("Test Loss:", round(test_loss, 4))


# Step 8: Plot Training History
# ----------------------------
plt.figure(figsize=(12,5))

# Accuracy plot
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.title('Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)


# Loss plot
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss', marker='o')
plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')
plt.title('Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()


# Step 9: Make Predictions
# ----------------------------
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)

# Convert one-hot labels back to integers
y_true = np.argmax(y_test, axis=1)

# Example: Display first test image and predicted class
plt.imshow(X_test[0])
plt.title(f"Predicted: {predicted_classes[0]}, True: {y_true[0]}")
plt.axis('off')
plt.show()

# Step 10: Classification Report
# ----------------------------
print("Classification Report:\n")
print(classification_report(y_true, predicted_classes, digits=4))
